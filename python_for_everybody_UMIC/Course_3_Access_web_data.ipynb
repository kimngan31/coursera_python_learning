{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGULAR EXPRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '19', '42']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'My 2 favorite numbers are 19 and 42'\n",
    "y = re.findall('[0-9]+',x)  \n",
    "print(y)\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d 4']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[Madn]\\s.+?',x) ##greedy and nongreedy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fav', 'rit', 'ber', 'are', 'and']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[MYfirabc].\\S+?',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stephen.marquard@uct.ac.za']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email = 'From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008'\n",
    "re.findall( '\\S+?@\\S+',email) ##greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['z@g']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\S?@\\S+?',email) ##non-greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCESS WEB DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\r\n",
      "Date: Sun, 30 Dec 2018 02:23:18 GMT\r\n",
      "Server: Apache/2.4.18 (Ubuntu)\r\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\r\n",
      "ETag: \"1d3-54f6609240717\"\r\n",
      "Accept-Ranges: bytes\r\n",
      "Content-Length: 467\r\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\r\n",
      "Pragma: no-cache\r\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\r\n",
      "Connection: close\r\n",
      "Content-Type: text/plain\r\n",
      "\r\n",
      "Why should you learn to write programs?\n",
      "\n",
      "Writing programs (or programming) is a very creative \n",
      "and rewarding activity.  You can write programs for \n",
      "many reasons, ranging from making your living to solving\n",
      "a difficult data analysis problem to having fun to helping\n",
      "someone else solve a problem.  This book assumes that \n",
      "everyone needs to know how to program, and that once \n",
      "you know how to program you will figure out what you want \n",
      "to do with your newfound skills.  \n"
     ]
    }
   ],
   "source": [
    "##the long way\n",
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/intro-short.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('G') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = b'a'\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = 'GET http://data.pr4e.org/intro-short.txt HTTP/1.0\\r\\n\\r\\n'.encode()  ##by default encode is converting UTF8/ASCII to bytes\n",
    "type(cmd)\n",
    "##and then .decode() the data - by default converting bytes to utf8/ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "#the short way\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())  #the fhand line still needs to be .decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEB SCRAPING - a program that pretends to be a browser\n",
    "Be careful some websites may be snippy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue: Cannot import beautifulsoup even though bs4 was installed. \n",
    "\n",
    "Solution : Just go to your python file where it is installed  C:\\python\\Lib\\site-packages and then copy bs4 and beautifulsoup4-4.6.0.dist-info folders and paste it to your project folder where you have saved your working project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the easyway - install Beautiflul Soup: https://pypi.org/project/beautifulsoup4/: pip install beautifulsoup4 \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter - http://www.dr-chuck.com\n",
      "TAG: <a href=\"https://www.dr-chuck.com/csev-blog/\">\n",
      "<img align=\"center\" alt=\"Photo Credit: Ian Dolphin\" src=\"csev_ian_dolphin_small.jpg\" width=\"160\"/>\n",
      "</a>\n",
      "URL: https://www.dr-chuck.com/csev-blog/\n",
      "Target: None\n",
      "Contents: \n",
      "\n",
      "Attrs: {'href': 'https://www.dr-chuck.com/csev-blog/'}\n",
      "TAG: <a href=\"https://www.si.umich.edu/\" target=\"_blank\">School of Information</a>\n",
      "URL: https://www.si.umich.edu/\n",
      "Target: _blank\n",
      "Contents: School of Information\n",
      "Attrs: {'href': 'https://www.si.umich.edu/', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.ratemyprofessors.com/ShowRatings.jsp?tid=1159280\" target=\"_blank\">\n",
      "<img alt=\"Rate This Professor\" src=\"/images/rate-my-professor.jpg\" width=\"140\"/></a>\n",
      "URL: https://www.ratemyprofessors.com/ShowRatings.jsp?tid=1159280\n",
      "Target: _blank\n",
      "Contents: \n",
      "\n",
      "Attrs: {'href': 'https://www.ratemyprofessors.com/ShowRatings.jsp?tid=1159280', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.dr-chuck.com/csev-blog/\">Blog</a>\n",
      "URL: https://www.dr-chuck.com/csev-blog/\n",
      "Target: None\n",
      "Contents: Blog\n",
      "Attrs: {'href': 'https://www.dr-chuck.com/csev-blog/'}\n",
      "TAG: <a href=\"https://www.twitter.com/drchuck/\" target=\"_blank\">@drchuck Twitter</a>\n",
      "URL: https://www.twitter.com/drchuck/\n",
      "Target: _blank\n",
      "Contents: @drchuck Twitter\n",
      "Attrs: {'href': 'https://www.twitter.com/drchuck/', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.dr-chuck.com/dr-chuck/resume/speaking.htm\" target=\"_blank\">Keynote Speaker</a>\n",
      "URL: https://www.dr-chuck.com/dr-chuck/resume/speaking.htm\n",
      "Target: _blank\n",
      "Contents: Keynote Speaker\n",
      "Attrs: {'href': 'https://www.dr-chuck.com/dr-chuck/resume/speaking.htm', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.slideshare.net/csev\" target=\"_blank\">Slideshare</a>\n",
      "URL: https://www.slideshare.net/csev\n",
      "Target: _blank\n",
      "Contents: Slideshare\n",
      "Attrs: {'href': 'https://www.slideshare.net/csev', 'target': '_blank'}\n",
      "TAG: <a href=\"/dr-chuck/resume/index.htm\" target=\"_blank\">Resume and Bio</a>\n",
      "URL: /dr-chuck/resume/index.htm\n",
      "Target: _blank\n",
      "Contents: Resume and Bio\n",
      "Attrs: {'href': '/dr-chuck/resume/index.htm', 'target': '_blank'}\n",
      "TAG: <a href=\"https://amzn.to/1K5Q81K\" target=\"_blank\">Amazon Author Page</a>\n",
      "URL: https://amzn.to/1K5Q81K\n",
      "Target: _blank\n",
      "Contents: Amazon Author Page\n",
      "Attrs: {'target': '_blank', 'href': 'https://amzn.to/1K5Q81K'}\n",
      "TAG: <a href=\"http://afs.dr-chuck.com/papers/\" target=\"_blank\">Chuck's Papers</a>\n",
      "URL: http://afs.dr-chuck.com/papers/\n",
      "Target: _blank\n",
      "Contents: Chuck's Papers\n",
      "Attrs: {'href': 'http://afs.dr-chuck.com/papers/', 'target': '_blank'}\n",
      "TAG: <a href=\"https://itunes.apple.com/us/podcast/computing-conversations/id731495760\" target=\"_blank\">IEEE Audio Podcast</a>\n",
      "URL: https://itunes.apple.com/us/podcast/computing-conversations/id731495760\n",
      "Target: _blank\n",
      "Contents: IEEE Audio Podcast\n",
      "Attrs: {'href': 'https://itunes.apple.com/us/podcast/computing-conversations/id731495760', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R\" target=\"_blank\">IEEE Video Interviews</a>\n",
      "URL: https://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R\n",
      "Target: _blank\n",
      "Contents: IEEE Video Interviews\n",
      "Attrs: {'href': 'https://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R', 'target': '_blank'}\n",
      "TAG: <a href=\"https://developers.imsglobal.org/\" target=\"_blank\">IMS LTI</a>\n",
      "URL: https://developers.imsglobal.org/\n",
      "Target: _blank\n",
      "Contents: IMS LTI\n",
      "Attrs: {'href': 'https://developers.imsglobal.org/', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.youtube.com/user/csev\" target=\"_blank\">YouTube Channel </a>\n",
      "URL: https://www.youtube.com/user/csev\n",
      "Target: _blank\n",
      "Contents: YouTube Channel \n",
      "Attrs: {'href': 'https://www.youtube.com/user/csev', 'target': '_blank'}\n",
      "TAG: <a href=\"https://vimeo.com/drchuck/videos\" target=\"_blank\">Video on Vimeo</a>\n",
      "URL: https://vimeo.com/drchuck/videos\n",
      "Target: _blank\n",
      "Contents: Video on Vimeo\n",
      "Attrs: {'href': 'https://vimeo.com/drchuck/videos', 'target': '_blank'}\n",
      "TAG: <a href=\"https://backpack.openbadges.org/share/4f76699ddb399d162a00b89a452074b3/\" target=\"_blank\">My Open Badges</a>\n",
      "URL: https://backpack.openbadges.org/share/4f76699ddb399d162a00b89a452074b3/\n",
      "Target: _blank\n",
      "Contents: My Open Badges\n",
      "Attrs: {'href': 'https://backpack.openbadges.org/share/4f76699ddb399d162a00b89a452074b3/', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.linkedin.com/in/charlesseverance/\" target=\"_blank\">\n",
      "<img alt=\"View Chuck Severance's profile on LinkedIn\" border=\"0\" height=\"33\" src=\"https://www.linkedin.com/img/webpromo/btn_viewmy_120x33.png\" width=\"120\"/>\n",
      "</a>\n",
      "URL: https://www.linkedin.com/in/charlesseverance/\n",
      "Target: _blank\n",
      "Contents: \n",
      "\n",
      "Attrs: {'href': 'https://www.linkedin.com/in/charlesseverance/', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.researchgate.net/profile/Charles_Severance/\" target=\"_blank\" title=\"Charles R. Severance\"><img alt=\"Charles R. Severance\" src=\"https://www.researchgate.net/images/public/profile_share_badge.png\"/></a>\n",
      "URL: https://www.researchgate.net/profile/Charles_Severance/\n",
      "Target: _blank\n",
      "Contents: <img alt=\"Charles R. Severance\" src=\"https://www.researchgate.net/images/public/profile_share_badge.png\"/>\n",
      "Attrs: {'title': 'Charles R. Severance', 'href': 'https://www.researchgate.net/profile/Charles_Severance/', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.tsugicloud.org/\" target=\"_blank\">TsugiCloud - An Educational App Store</a>\n",
      "URL: https://www.tsugicloud.org/\n",
      "Target: _blank\n",
      "Contents: TsugiCloud - An Educational App Store\n",
      "Attrs: {'href': 'https://www.tsugicloud.org/', 'target': '_blank'}\n",
      "TAG: <a href=\"/office\" target=\"_blank\">MOOC Office Hours Around the World</a>\n",
      "URL: /office\n",
      "Target: _blank\n",
      "Contents: MOOC Office Hours Around the World\n",
      "Attrs: {'href': '/office', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.coursera.org/course/pythonlearn\" target=\"_blank\">Coursera: Programming for Everybody</a>\n",
      "URL: https://www.coursera.org/course/pythonlearn\n",
      "Target: _blank\n",
      "Contents: Coursera: Programming for Everybody\n",
      "Attrs: {'href': 'https://www.coursera.org/course/pythonlearn', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.coursera.org/course/insidetheinternet\" target=\"_blank\">Coursera: Internet History, Technnology and Security</a>\n",
      "URL: https://www.coursera.org/course/insidetheinternet\n",
      "Target: _blank\n",
      "Contents: Coursera: Internet History, Technnology and Security\n",
      "Attrs: {'href': 'https://www.coursera.org/course/insidetheinternet', 'target': '_blank'}\n",
      "TAG: <a href=\"https://open.umich.edu/education/si/si502/winter2009/\" target=\"_blank\">SI 502 - Networked Computing</a>\n",
      "URL: https://open.umich.edu/education/si/si502/winter2009/\n",
      "Target: _blank\n",
      "Contents: SI 502 - Networked Computing\n",
      "Attrs: {'href': 'https://open.umich.edu/education/si/si502/winter2009/', 'target': '_blank'}\n",
      "TAG: <a href=\"http://www.pythonlearn.com\" target=\"_blank\">www.pythonlearn.com</a>\n",
      "URL: http://www.pythonlearn.com\n",
      "Target: _blank\n",
      "Contents: www.pythonlearn.com\n",
      "Attrs: {'href': 'http://www.pythonlearn.com', 'target': '_blank'}\n",
      "TAG: <a href=\"http://www.php-intro.com/\" target=\"_blank\">\n",
      "www.php-intro.com</a>\n",
      "URL: http://www.php-intro.com/\n",
      "Target: _blank\n",
      "Contents: \n",
      "www.php-intro.com\n",
      "Attrs: {'href': 'http://www.php-intro.com/', 'target': '_blank'}\n",
      "TAG: <a href=\"http://www.appenginelearn.com/\">\n",
      "www.appenginelearn.com</a>\n",
      "URL: http://www.appenginelearn.com/\n",
      "Target: None\n",
      "Contents: \n",
      "www.appenginelearn.com\n",
      "Attrs: {'href': 'http://www.appenginelearn.com/'}\n",
      "TAG: <a href=\"http://www.pythonlearn.com/\" target=\"_blank\">Python For Informatics: Exploring Information</a>\n",
      "URL: http://www.pythonlearn.com/\n",
      "Target: _blank\n",
      "Contents: Python For Informatics: Exploring Information\n",
      "Attrs: {'href': 'http://www.pythonlearn.com/', 'target': '_blank'}\n",
      "TAG: <a href=\"/sakai-book\">Sakai: Building an Open Source Community</a>\n",
      "URL: /sakai-book\n",
      "Target: None\n",
      "Contents: Sakai: Building an Open Source Community\n",
      "Attrs: {'href': '/sakai-book'}\n",
      "TAG: <a href=\"http://www.amazon.com/gp/product/1624311393/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1624311393&amp;linkCode=as2&amp;tag=drchu02-20\" target=\"_blank\">Raspberry Pi (21st Century Skills Innovation Library)</a>\n",
      "URL: http://www.amazon.com/gp/product/1624311393/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1624311393&linkCode=as2&tag=drchu02-20\n",
      "Target: _blank\n",
      "Contents: Raspberry Pi (21st Century Skills Innovation Library)\n",
      "Attrs: {'href': 'http://www.amazon.com/gp/product/1624311393/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1624311393&linkCode=as2&tag=drchu02-20', 'target': '_blank'}\n",
      "TAG: <a href=\"http://www.amazon.com/gp/product/059680069X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=059680069X&amp;linkCode=as2&amp;tag=drchu02-20\" target=\"_blank\">Using Google App Engine</a>\n",
      "URL: http://www.amazon.com/gp/product/059680069X/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=059680069X&linkCode=as2&tag=drchu02-20\n",
      "Target: _blank\n",
      "Contents: Using Google App Engine\n",
      "Attrs: {'href': 'http://www.amazon.com/gp/product/059680069X/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=059680069X&linkCode=as2&tag=drchu02-20', 'target': '_blank'}\n",
      "TAG: <a href=\"http://www.amazon.com/Performance-Computing-Architectures-Optimization-Benchmarks/dp/156592312X/\" target=\"_blank\">High Performance Computing</a>\n",
      "URL: http://www.amazon.com/Performance-Computing-Architectures-Optimization-Benchmarks/dp/156592312X/\n",
      "Target: _blank\n",
      "Contents: High Performance Computing\n",
      "Attrs: {'href': 'http://www.amazon.com/Performance-Computing-Architectures-Optimization-Benchmarks/dp/156592312X/', 'target': '_blank'}\n",
      "TAG: <a href=\"http://oreilly.com/catalog/9781565923126/\" target=\"_blank\">O'Reilly 1998</a>\n",
      "URL: http://oreilly.com/catalog/9781565923126/\n",
      "Target: _blank\n",
      "Contents: O'Reilly 1998\n",
      "Attrs: {'href': 'http://oreilly.com/catalog/9781565923126/', 'target': '_blank'}\n",
      "TAG: <a href=\"http://cnx.org/content/col11136/latest/\" target=\"_blank\">Connexions 2010</a>\n",
      "URL: http://cnx.org/content/col11136/latest/\n",
      "Target: _blank\n",
      "Contents: Connexions 2010\n",
      "Attrs: {'href': 'http://cnx.org/content/col11136/latest/', 'target': '_blank'}\n",
      "TAG: <a href=\"http://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R\" target=\"_blank\">\n",
      "IEEE Computer - Computing Conversations Interviews</a>\n",
      "URL: http://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R\n",
      "Target: _blank\n",
      "Contents: \n",
      "IEEE Computer - Computing Conversations Interviews\n",
      "Attrs: {'href': 'http://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.vimeo.com/17207620\" target=\"_blank\">\n",
      "Dr. Chuck sings the blues </a>\n",
      "URL: https://www.vimeo.com/17207620\n",
      "Target: _blank\n",
      "Contents: \n",
      "Dr. Chuck sings the blues \n",
      "Attrs: {'href': 'https://www.vimeo.com/17207620', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.youtube.com/watch?v=BVKpW02hsrU\" target=\"_blank\">\n",
      "Dr. Chuck goes motocross racing</a>\n",
      "URL: https://www.youtube.com/watch?v=BVKpW02hsrU\n",
      "Target: _blank\n",
      "Contents: \n",
      "Dr. Chuck goes motocross racing\n",
      "Attrs: {'href': 'https://www.youtube.com/watch?v=BVKpW02hsrU', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.youtube.com/watch?v=sa2WsgCvn7c\" target=\"_blank\">\n",
      "A Film About Brent and His ATV\n",
      "</a>\n",
      "URL: https://www.youtube.com/watch?v=sa2WsgCvn7c\n",
      "Target: _blank\n",
      "Contents: \n",
      "A Film About Brent and His ATV\n",
      "\n",
      "Attrs: {'href': 'https://www.youtube.com/watch?v=sa2WsgCvn7c', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.vimeo.com/17213019\" target=\"_blank\">\n",
      "Audition Tape</a>\n",
      "URL: https://www.vimeo.com/17213019\n",
      "Target: _blank\n",
      "Contents: \n",
      "Audition Tape\n",
      "Attrs: {'href': 'https://www.vimeo.com/17213019', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.youtube.com/watch?v=FJ078sO35M0\" target=\"_blank\">\n",
      "Dr. Chuck goes stock car racing</a>\n",
      "URL: https://www.youtube.com/watch?v=FJ078sO35M0\n",
      "Target: _blank\n",
      "Contents: \n",
      "Dr. Chuck goes stock car racing\n",
      "Attrs: {'href': 'https://www.youtube.com/watch?v=FJ078sO35M0', 'target': '_blank'}\n",
      "TAG: <a href=\"http://afs.dr-chuck.com/citoolkit\" target=\"_blank\">\n",
      "The Community Information Toolkit</a>\n",
      "URL: http://afs.dr-chuck.com/citoolkit\n",
      "Target: _blank\n",
      "Contents: \n",
      "The Community Information Toolkit\n",
      "Attrs: {'href': 'http://afs.dr-chuck.com/citoolkit', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.sakaiproject.org/\" target=\"_blank\">The Sakai Collaboration\n",
      "and Learning Environment</a>\n",
      "URL: https://www.sakaiproject.org/\n",
      "Target: _blank\n",
      "Contents: The Sakai Collaboration\n",
      "and Learning Environment\n",
      "Attrs: {'href': 'https://www.sakaiproject.org/', 'target': '_blank'}\n",
      "TAG: <a href=\"https://www.tsugi.org/\" target=\"_blank\">Tsugi: A framework for IMS LTI Tools</a>\n",
      "URL: https://www.tsugi.org/\n",
      "Target: _blank\n",
      "Contents: Tsugi: A framework for IMS LTI Tools\n",
      "Attrs: {'href': 'https://www.tsugi.org/', 'target': '_blank'}\n",
      "TAG: <a href=\"https://developers.imsglobal.org/\" target=\"_blank\">IMS Learning Tools\n",
      "Interoperability</a>\n",
      "URL: https://developers.imsglobal.org/\n",
      "Target: _blank\n",
      "Contents: IMS Learning Tools\n",
      "Interoperability\n",
      "Attrs: {'href': 'https://developers.imsglobal.org/', 'target': '_blank'}\n",
      "TAG: <a href=\"/obi-sample\" target=\"_blank\">My Reference Implementation of Mozilla Open Badges in PHP</a>\n",
      "URL: /obi-sample\n",
      "Target: _blank\n",
      "Contents: My Reference Implementation of Mozilla Open Badges in PHP\n",
      "Attrs: {'href': '/obi-sample', 'target': '_blank'}\n",
      "TAG: <a class=\"twitter-timeline\" data-widget-id=\"282172185219567616\" href=\"https://twitter.com/drchuck\">Tweets by @drchuck</a>\n",
      "URL: https://twitter.com/drchuck\n",
      "Target: None\n",
      "Contents: Tweets by @drchuck\n",
      "Attrs: {'class': ['twitter-timeline'], 'href': 'https://twitter.com/drchuck', 'data-widget-id': '282172185219567616'}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')  ##type = 'bs4.element.ResultSet'. Change 'a' to the wrapper of the data to be extracted\n",
    "\n",
    "for tag in tags:\n",
    "    print('TAG:', tag)                        ##type = 'bs4.element.Tag'\n",
    "    print('Contents:', tag.contents[0])       ##tag.contents -- is a list \n",
    "    print('Attrs:', tag.attrs)       ##tag.attrs -- dictionary with different attributes (pair key/values). e.g href, target\n",
    "    print('URL:', tag.get('href', None))      #getting the value of the attribute url if any - output string \n",
    "    print('Target:', tag.get('target',None))  #getting the value of the attribute target if any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT 1 Scraping Numbers from HTML using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will write a Python program similar to http://www.py4e.com/code3/urllink2.py. The program will use urllib to read the HTML from the data files below, and parse the data, extracting numbers and compute the sum of the numbers in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter - http://py4e-data.dr-chuck.net/comments_42.html\n",
      "2553.0\n"
     ]
    }
   ],
   "source": [
    "#example script:\n",
    "# To run this, you can install BeautifulSoup\n",
    "# https://pypi.python.org/pypi/beautifulsoup4\n",
    "\n",
    "# Or download the file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "#url = 'http://py4e-data.dr-chuck.net/comments_42.html' --for testing\n",
    "html = urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('span')  #Use 'span' because it is used to wrap the numbers\n",
    "total = 0\n",
    "for tag in tags:\n",
    "    num = float(tag.contents[0])\n",
    "    total = total + num \n",
    "print(total)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT 2  -- Following Links in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will write a Python program that expands on http://www.py4e.com/code3/urllinks.py. The program will use urllib to read the HTML from the data files below, extract the href= vaues from the anchor tags, scan for a tag that is in a particular position relative to the first name in the list, follow that link and repeat the process a number of times and report the last name you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter URL - http://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
      "Enter count: 4\n",
      "Enter position: 15\n",
      "Faith\n"
     ]
    }
   ],
   "source": [
    "# To run this, you can install BeautifulSoup\n",
    "# https://pypi.python.org/pypi/beautifulsoup4\n",
    "\n",
    "# Or download the file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "#input setting\n",
    "initial_url = input('Enter URL - ')\n",
    "#initial_url = 'http://py4e-data.dr-chuck.net/known_by_Fikret.html' #for testing\n",
    "n          = int(input('Enter count: ') )     # number of iterations to be determined by the assignment\n",
    "pos        = int(input('Enter position: ') )      # position of url  to be determined by the assignment\n",
    "\n",
    "\n",
    "# GETTING THE NAME \n",
    "for i in range(n):\n",
    "    # specify the url to open: initial_url at the beginning and specified position going forward\n",
    "    if i == 0:\n",
    "        url = initial_url\n",
    "    else:\n",
    "        url = tags[pos-1].get('href',None)  \n",
    "    \n",
    "    # open the url, use BeautifulSoup to transform and get the data with anchor ('a') tag\n",
    "    html = urlopen(url, context=ctx).read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    tags = soup('a')\n",
    "\n",
    "    #get the name at the specified position - first in the list \n",
    "    name = (tags[pos-1].contents[0])\n",
    "    \n",
    "#print the final name \n",
    "print(name) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKING WITH XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appearance similar to HTML. We used beautifulsoup to read HTML, now we will use ElementTree to read XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Chuck\n",
      "Attr: yes\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "data = '''\n",
    "<person>\n",
    "  <name>Chuck</name>\n",
    "  <phone type=\"intl\">\n",
    "    +1 734 303 4456\n",
    "  </phone>\n",
    "  <email hide=\"yes\" />\n",
    "</person>'''\n",
    "\n",
    "tree = ET.fromstring(data)  #<class 'xml.etree.ElementTree.Element'>\n",
    "print('Name:', tree.find('name').text)     # --> find element 'name', and get the text (vs. attribute) part\n",
    "print('Attr:', tree.find('email').get('hide'))  # --> get element email and find the attribute 'hide' within it.\n",
    "\n",
    "#tree.find('name') is Element. And then use.text and get('attribute')  to get to the data underneath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[<Element 'user' at 0x0000025F00377868>, <Element 'user' at 0x0000025F00377D68>]\n",
      "User count: 2\n",
      "Name Chuck\n",
      "Id 001\n",
      "Attribute 2\n",
      "Name Brent\n",
      "Id 009\n",
      "Attribute 7\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "input = '''\n",
    "<stuff>\n",
    "  <users>\n",
    "    <user x=\"2\">\n",
    "      <id>001</id>\n",
    "      <name>Chuck</name>\n",
    "    </user>\n",
    "    <user x=\"7\">\n",
    "      <id>009</id>\n",
    "      <name>Brent</name>\n",
    "    </user>\n",
    "  </users>\n",
    "</stuff>'''\n",
    "\n",
    "stuff = ET.fromstring(input)\n",
    "lst = stuff.findall('users/user')  #will be a list\n",
    "print(type(lst))\n",
    "print(lst)\n",
    "print('User count:', len(lst))\n",
    "\n",
    "for item in lst:\n",
    "    print('Name', item.find('name').text)\n",
    "    print('Id', item.find('id').text)\n",
    "    print('Attribute', item.get('x'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the code a little simpler, you can use an XPath selector string to look through the entire tree of XML for any tag named 'count' with the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = tree.findall('.//count') #this is similar to soup('xxx') in beautiful soup\n",
    "## vs. using specific path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import xml.etree.ElementTree as ET\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "#get the URL\n",
    "url = 'http://py4e-data.dr-chuck.net/comments_42.xml' #for testing only\n",
    "url = input('Enter URL: ')\n",
    "\n",
    "data = urllib.request.urlopen(url, context=ctx).read()  #open the data\n",
    "tree = ET.fromstring(data)                              #use ET to convert to Tree format\n",
    "\n",
    "counts = tree.findall('.//count')     #get to the right path. Equivalent to: tree.findall('comments/comment/count')  \n",
    "total = 0\n",
    "for item in counts:\n",
    "    num = float(item.text)\n",
    "    total = total + num\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON - JavaScript Object Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter location: 1900 Key blvd\n",
      "Retrieving http://py4e-data.dr-chuck.net/json?address=1900+Key+blvd&key=42\n",
      "Retrieved 2440 characters\n",
      "{\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"address_components\": [\n",
      "                {\n",
      "                    \"long_name\": \"1900\",\n",
      "                    \"short_name\": \"1900\",\n",
      "                    \"types\": [\n",
      "                        \"street_number\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Key Boulevard\",\n",
      "                    \"short_name\": \"Key Blvd\",\n",
      "                    \"types\": [\n",
      "                        \"route\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Colonial Village\",\n",
      "                    \"short_name\": \"Colonial Village\",\n",
      "                    \"types\": [\n",
      "                        \"neighborhood\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Arlington\",\n",
      "                    \"short_name\": \"Arlington\",\n",
      "                    \"types\": [\n",
      "                        \"locality\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Arlington County\",\n",
      "                    \"short_name\": \"Arlington County\",\n",
      "                    \"types\": [\n",
      "                        \"administrative_area_level_2\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Virginia\",\n",
      "                    \"short_name\": \"VA\",\n",
      "                    \"types\": [\n",
      "                        \"administrative_area_level_1\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"United States\",\n",
      "                    \"short_name\": \"US\",\n",
      "                    \"types\": [\n",
      "                        \"country\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"22201\",\n",
      "                    \"short_name\": \"22201\",\n",
      "                    \"types\": [\n",
      "                        \"postal_code\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"3231\",\n",
      "                    \"short_name\": \"3231\",\n",
      "                    \"types\": [\n",
      "                        \"postal_code_suffix\"\n",
      "                    ]\n",
      "                }\n",
      "            ],\n",
      "            \"formatted_address\": \"1900 Key Blvd, Arlington, VA 22201, USA\",\n",
      "            \"geometry\": {\n",
      "                \"location\": {\n",
      "                    \"lat\": 38.894474,\n",
      "                    \"lng\": -77.08266400000001\n",
      "                },\n",
      "                \"location_type\": \"ROOFTOP\",\n",
      "                \"viewport\": {\n",
      "                    \"northeast\": {\n",
      "                        \"lat\": 38.8958229802915,\n",
      "                        \"lng\": -77.08131501970851\n",
      "                    },\n",
      "                    \"southwest\": {\n",
      "                        \"lat\": 38.8931250197085,\n",
      "                        \"lng\": -77.08401298029152\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            \"place_id\": \"ChIJqXOV_2C2t4kRkn_sPMpuasU\",\n",
      "            \"plus_code\": {\n",
      "                \"compound_code\": \"VWV8+QW Arlington, Mason, VA, United States\",\n",
      "                \"global_code\": \"87C4VWV8+QW\"\n",
      "            },\n",
      "            \"types\": [\n",
      "                \"street_address\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"status\": \"OK\"\n",
      "}\n",
      "lat 38.894474 lng -77.08266400000001\n",
      "Location 1900 Key Blvd, Arlington, VA 22201, USA\n",
      "Enter location: 1600 Capital One Dr McLean\n",
      "Retrieving http://py4e-data.dr-chuck.net/json?address=1600+Capital+One+Dr+McLean&key=42\n",
      "Retrieved 2297 characters\n",
      "{\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"address_components\": [\n",
      "                {\n",
      "                    \"long_name\": \"1600\",\n",
      "                    \"short_name\": \"1600\",\n",
      "                    \"types\": [\n",
      "                        \"street_number\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Capital One Drive\",\n",
      "                    \"short_name\": \"Capital One Dr\",\n",
      "                    \"types\": [\n",
      "                        \"route\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"McLean\",\n",
      "                    \"short_name\": \"McLean\",\n",
      "                    \"types\": [\n",
      "                        \"locality\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Providence\",\n",
      "                    \"short_name\": \"Providence\",\n",
      "                    \"types\": [\n",
      "                        \"administrative_area_level_3\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Fairfax County\",\n",
      "                    \"short_name\": \"Fairfax County\",\n",
      "                    \"types\": [\n",
      "                        \"administrative_area_level_2\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"Virginia\",\n",
      "                    \"short_name\": \"VA\",\n",
      "                    \"types\": [\n",
      "                        \"administrative_area_level_1\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"United States\",\n",
      "                    \"short_name\": \"US\",\n",
      "                    \"types\": [\n",
      "                        \"country\",\n",
      "                        \"political\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"long_name\": \"22102\",\n",
      "                    \"short_name\": \"22102\",\n",
      "                    \"types\": [\n",
      "                        \"postal_code\"\n",
      "                    ]\n",
      "                }\n",
      "            ],\n",
      "            \"formatted_address\": \"1600 Capital One Dr, McLean, VA 22102, USA\",\n",
      "            \"geometry\": {\n",
      "                \"location\": {\n",
      "                    \"lat\": 38.9262745,\n",
      "                    \"lng\": -77.2116837\n",
      "                },\n",
      "                \"location_type\": \"ROOFTOP\",\n",
      "                \"viewport\": {\n",
      "                    \"northeast\": {\n",
      "                        \"lat\": 38.92762348029149,\n",
      "                        \"lng\": -77.21033471970848\n",
      "                    },\n",
      "                    \"southwest\": {\n",
      "                        \"lat\": 38.92492551970849,\n",
      "                        \"lng\": -77.21303268029149\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            \"place_id\": \"ChIJO2K2ssBKtokREZzXGsZCsAQ\",\n",
      "            \"plus_code\": {\n",
      "                \"compound_code\": \"WQGQ+G8 Tysons, Providence, VA, United States\",\n",
      "                \"global_code\": \"87C4WQGQ+G8\"\n",
      "            },\n",
      "            \"types\": [\n",
      "                \"street_address\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"status\": \"OK\"\n",
      "}\n",
      "lat 38.9262745 lng -77.2116837\n",
      "Location 1600 Capital One Dr, McLean, VA 22102, USA\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import json\n",
    "import ssl\n",
    "\n",
    "api_key = False\n",
    "# If you have a Google Places API key, enter it here\n",
    "# api_key = 'AIzaSy___IDByT70'\n",
    "# https://developers.google.com/maps/documentation/geocoding/intro\n",
    "\n",
    "if api_key is False:\n",
    "    api_key = 42\n",
    "    serviceurl = 'http://py4e-data.dr-chuck.net/json?'\n",
    "else :\n",
    "    serviceurl = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    parms = dict()\n",
    "    parms['address'] = address\n",
    "    if api_key is not False: parms['key'] = api_key\n",
    "    url = serviceurl + urllib.parse.urlencode(parms)\n",
    "\n",
    "    print('Retrieving', url)\n",
    "    uh = urllib.request.urlopen(url, context=ctx)\n",
    "    data = uh.read().decode()\n",
    "    print('Retrieved', len(data), 'characters')\n",
    "\n",
    "    try:\n",
    "        js = json.loads(data)   ##this will give a dictionary\n",
    "    except:\n",
    "        js = None\n",
    "\n",
    "    if not js or 'status' not in js or js['status'] != 'OK':\n",
    "        print('==== Failure To Retrieve ====')\n",
    "        print(data)\n",
    "        continue\n",
    "\n",
    "    print(json.dumps(js, indent=4))\n",
    "\n",
    "    lat = js['results'][0]['geometry']['location']['lat']\n",
    "    lng = js['results'][0]['geometry']['location']['lng']\n",
    "    print('lat', lat, 'lng', lng)\n",
    "    location = js['results'][0]['formatted_address']\n",
    "    print('Location', location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will write a Python program somewhat similar to http://www.py4e.com/code3/json2.py. The program will prompt for a URL, read the JSON data from that URL using urllib and then parse and extract the comment counts from the JSON data, compute the sum of the numbers in the file and enter the sum below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter URL: http://py4e-data.dr-chuck.net/comments_96685.json\n",
      "2469.0\n"
     ]
    }
   ],
   "source": [
    "#import necessary stuff\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "#import xml.etree.ElementTree as ET       ##import this for XML\n",
    "#from bs4 import BeautifulSoup            ##import this for HTML\n",
    "import json                              ##import this for JSON\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors ##ALWAYS USE THIS\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "#get the URL\n",
    "#url = 'http://py4e-data.dr-chuck.net/comments_42.json' #for testing only\n",
    "url = input('Enter URL: ')\n",
    "\n",
    "#Open the file: urlopen() is like file handle. And then .read() . And convert to readable json\n",
    "data = urllib.request.urlopen(url, context=ctx).read().decode()  #open the data and decode\n",
    "info = json.loads(data)\n",
    "\n",
    "#extract the JSON data elements\n",
    "total = 0\n",
    "for item in info['comments']:\n",
    "    num = float(item['count'])\n",
    "    total = total + num\n",
    "    \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import json\n",
    "import ssl\n",
    "\n",
    "api_key = False\n",
    "# If you have a Google Places API key, enter it here\n",
    "# api_key = 'AIzaSy___IDByT70'\n",
    "# https://developers.google.com/maps/documentation/geocoding/intro\n",
    "\n",
    "if api_key is False:\n",
    "    api_key = 42\n",
    "    serviceurl = 'http://py4e-data.dr-chuck.net/json?'\n",
    "else :\n",
    "    serviceurl = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    parms = dict()\n",
    "    parms['address'] = address\n",
    "    if api_key is not False: parms['key'] = api_key\n",
    "    url = serviceurl + urllib.parse.urlencode(parms)\n",
    "\n",
    "    print('Retrieving', url)\n",
    "    uh = urllib.request.urlopen(url, context=ctx)\n",
    "    data = uh.read().decode()\n",
    "    print('Retrieved', len(data), 'characters')\n",
    "\n",
    "    try:\n",
    "        js = json.loads(data)\n",
    "    except:\n",
    "        js = None\n",
    "\n",
    "    if not js or 'status' not in js or js['status'] != 'OK':\n",
    "        print('==== Failure To Retrieve ====')\n",
    "        print(data)\n",
    "        continue\n",
    "\n",
    "    print(json.dumps(js, indent=4))\n",
    "\n",
    "    location = js['results'][0]['formatted_address']\n",
    "    print(location)\n",
    "\n",
    "    place_id = js['results'][0]['place_id']\n",
    "    print(place_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUMMARY OF WEB SCRAPING WITH ELEMENT TREE / BEAUTIFUL SOUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary stuff\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import xml.etree.ElementTree as ET       ##import this for XML\n",
    "from bs4 import BeautifulSoup            ##import this for HTML\n",
    "import json                              ##import this for JSON\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors ##ALWAYS USE THIS\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "\n",
    "#get the URL\n",
    "url = 'http://py4e-data.dr-chuck.net/comments_42.xml' #for testing only\n",
    "url = input('Enter url: ')\n",
    "#or some manipulated URL if used for API\n",
    "\n",
    "#Open the file: urlopen() is like file handle. And then .read() & decode()\n",
    "data = urllib.request.urlopen(url, context=ctx).read().decode()  #open the data\n",
    "#data = urllib.request.urlopen(url, context=ctx).read()          ##using .decode() is optional\n",
    "\n",
    "###### WITH XML - USE ELEMENT TREE: ##############\n",
    "#Convert the data to digestable format for python\n",
    "tree = ET.fromstring(data)                       \n",
    "\n",
    "#extraction method:\n",
    "counts = tree.findall('.//count')     #get to the right path. Equivalent to: tree.findall('comments/comment/count')  \n",
    "item.find('comment/name') #use .find() or .findall() to drill down to next level in the tree. findall() = a list of element\n",
    "\n",
    "item.find('etc').text #use .text to get to the content\n",
    "item.text             #use .text to get to the content\n",
    "\n",
    "item.find('etc').get('x', None)  #use .get('attribute_key') to get the value of the corresponding attribute key\n",
    "item.get('hide', None)           #use .get('attribute_key') to get the value of the corresponding attribute key\n",
    "\n",
    "\n",
    "###### WITH HTML - USE BEAUTIFUL SOUP: ##############\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "#extraction method:\n",
    "tags = soup('span')  #Use 'XXX' to specify the wrapper of the part want to extract \n",
    "#-- this will give a \"list\" that we can loop through\n",
    "\n",
    "for tag in tags:\n",
    "    print('TAG:', tag)                        ##type = 'bs4.element.Tag'\n",
    "    print('Contents:', tag.contents[0])       ##tag.contents -- is a list \n",
    "    print('Attrs:', tag.attrs)       ##tag.attrs -- dictionary with different attributes (pair key/values). e.g href, target\n",
    "    print('URL:', tag.get('href', None))      #getting the value of the attribute url if any - output string \n",
    "    print('Target:', tag.get('target',None))  #getting the value of the attribute target if any\n",
    "\n",
    "###### WITH JSON - USE JSON LIBRARY ##################\n",
    "    try:\n",
    "        js = json.loads(data)  #This will give a dictionary \n",
    "    except:\n",
    "        js = None\n",
    "\n",
    "#extraction method is simple with JSON - just a bunch of dictionaries and lists nested within each others: \n",
    "    location = js['results'][0]['formatted_address']\n",
    "    print(location)\n",
    "\n",
    "    place_id = js['results'][0]['place_id']\n",
    "    print(place_id)\n",
    "    \n",
    "    lat = js['results'][0]['geometry']['location']['lat']\n",
    "    lng = js['results'][0]['geometry']['location']['lng']\n",
    "    print('lat', lat, 'lng', lng)\n",
    "    \n",
    "#or can dump all the data: \n",
    "print(json.dumps(js, indent=4))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manipulate URL for API only -- this depends on specific API. For GoogleMap\n",
    "api_key = False\n",
    "# If you have a Google Places API key, enter it here\n",
    "# api_key = 'AIzaSy___IDByT70'\n",
    "# https://developers.google.com/maps/documentation/geocoding/intro\n",
    "\n",
    "if api_key is False:\n",
    "    api_key = 42\n",
    "    serviceurl = 'http://py4e-data.dr-chuck.net/json?'\n",
    "else :\n",
    "    serviceurl = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    parms = dict()\n",
    "    parms['address'] = address\n",
    "    if api_key is not False: parms['key'] = api_key\n",
    "    url = serviceurl + urllib.parse.urlencode(parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
